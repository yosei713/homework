{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21807f33",
   "metadata": {},
   "source": [
    "まず、ニュートラルネットワークでは左の層を入力層、真ん中を中間層(隠れ層)、右の層を出力層という。<br><br>\n",
    "# パーセプトロンの復習\n",
    "y=0 b+w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>≦0  \n",
    "y=1 b+w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>＞0  \n",
    "なお、bはバイアスを示す。  を簡略化するには\n",
    "y=h(b+w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>)として、  \n",
    "h(x)=0(x≦0)  h(x)=0(x＞0) とすることができる。<br><br>\n",
    "# 活性化関数  \n",
    "h(x)のような入力信号の総和を出力信号に変換する関数は一般に活性化関数呼ばれる。名前が示す通り、活性化関数は入力信号の総和がどのように活性化するかを決定する役割がある。  \n",
    "閾値を境にして出力が切り替わる関数を「ステップ関数」や「階段関数」と呼ぶ。\n",
    "活性化関数にステップ関数以外の関数を用いることで、ニューラルネットワークの世界へ進むことができる。<br><br>\n",
    "# シグモイド関数\n",
    "ニューラルネットワークでよく用いられる活性化関数の一つはシグモイド関数だ。  \n",
    "$$h(x)=\\frac{1}{1+exp(-x)}$$　\n",
    "なお、exp(x)はe<sup>-x</sup>を意味する。(eは2.7182…の実数を示す。)<br><br>\n",
    "# ステップ関数の実装  \n",
    "ここではpythonを用いてステップ関数をグラフtpする。  \n",
    "ステップ関数を単純に実装するならばいかのようになる。  \n",
    ">def step_function(x):\n",
    "   if x > 0:\n",
    "       return 1\n",
    "   else:\n",
    "       return 0 \n",
    "       \n",
    "しかし、以上のコードだとxが実数の場合のみしか入力ができないため、numpy配列を因数に引き取るような使い方ができない。そこで、numpy配列に対応した実装に修正する必要がある。\n",
    "\n",
    ">def step_function(x)  \n",
    "     y = x < 0\n",
    "     return y.astype(np.int)\n",
    "     \n",
    "numpy配列に対して不等号の演算を行うと配列の各要素に対して不等号の演算を行い、ブーリアンの配列が生成される。<br><br>\n",
    "# ステップ関数のグラフ\n",
    "上で定義したステップ関数のグラフを表すにはライブラリのmatplotlibを使用する。\n",
    ">import numpy as np  \n",
    "import matplotlib.pylab as plt  \n",
    "def step_function(x):  \n",
    "    return np.array(x > 0, dtype=np.int  \n",
    "    x = np,arange(-5.0, 5.0, 0.1)  \n",
    "    y = step_function(x)  \n",
    "    plot.plot(x,y)  \n",
    "    plt.ylim(-0.1, 1.1)  \n",
    "    plt show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ecd2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d82f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def step_function(x):\n",
    "    return np.array(x > 0, dtype=np.int)\n",
    "\n",
    "    x = np.arange(-5.0, 5.0, 0.1)\n",
    "    y = step_function(x)\n",
    "    plot.plot(x, y)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0300161b",
   "metadata": {},
   "source": [
    "# シグモイド関数の実装\n",
    "シグモイド関数は以下のように記される。\n",
    ">def sigmoid(x):  \n",
    "     return 1 / (1 + np.exp(-x))\n",
    "     \n",
    "ここではxにnumpy配列を入寮しても結果が正しく計算される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4e9177e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):  \n",
    "     return 1 / (1 + np.exp(-x))\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550bb1b2",
   "metadata": {},
   "source": [
    "# シグモイド関数とステップ関数の比較\n",
    "シグモイド関数が滑らかで連続した関数である一方で、ステップ関数は０を境に急に出力を変える関数である。このシグモイド関数の滑らかさがニューラルネットワークの学習において重要な意味を持つ。  \n",
    "しかし、両者は大きな視点で見ると同じような形をしており、両者とも入力が小さいほど出力は0に近く、入力が大きくなると１に近づくという構造をしている。よって両者は入力が重要ならば小さな値を出力し、その裏も成り立つといえる。  \n",
    "# 非線形関数\n",
    "また、両者の共通点はほかにも非線形であることがあげられる。シグモイド関数は曲線、ステップ関数は階段のように折れ曲がった直線であらわされるからだ。  \n",
    "ニューラルネットワークでは活性化関数に非線形関数を用いる必要がある。つまり、活性化関数に線形関数を用いてはならない。なぜなら、s根警官数にするならばニューラルネットワークで層を厚くする必要がないからだ。線形関数の問題点はどんなに層を深くしてもそれと同じことを行う隠れ層のないネットワークが必ず存在するという事実に起因する。\n",
    "# ReLU関数\n",
    "古くから利用されているシグモイド関数よりも、近年では主にReLU関数という関数が使われる。ReLuでは入力が０を超えていればその入力をそのまま出力し、0以下ならば0を出力する関数だ。  \n",
    "ReLU関数は以下のように記される。    \n",
    "h(x)=x (x≧0)  \n",
    "h(x)=0 (x<0)   \n",
    "ReLu関数はシンプルな関数であるため実装も簡単である。  \n",
    ">def relu(x):\n",
    "     return np.maximum(0, x)\n",
    "     \n",
    "maximum関数は入力された値から大きいほうを選んで出力する関数だ。\n",
    "# 多次元配列\n",
    "行列の計算などに関しては既習であるため省略させていただく。  \n",
    "配列の次元数は np.ndim()関数で、配列の形状はインスタンス変数の　shapeから取得できる。  \n",
    "行列の積はnumpyの関数 np.dot()で計算できる。当然A,Bの順番を入れ替えることはできない。  \n",
    "行列を用いることでニューラルネットワークの重みを一度の演算で処理することができる。これは実装上とても重要なテクニックだ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d233ce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0, 0.5])\n",
    "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "print(W1.shape)\n",
    "print(X.shape)\n",
    "print(B1.shape)\n",
    "\n",
    "A1 = np.dot(X, W1) + B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01bad367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "Z1 = sigmoid(A1 )\n",
    "\n",
    "print(A1)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7da475df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "B2 = np.array([0.1, 0.2])\n",
    "print(Z1.shape)\n",
    "print(W2.shape)\n",
    "print(B2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55277194",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = np.dot(Z1, W2) + B2\n",
    "Z2 = sigmoid(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6a2f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "B3 = np.array([0.1, 0.2])\n",
    "\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "Y = identity_function(A3)\n",
    "#入力をそのまま出力する関i数を恒等関数という。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4970e",
   "metadata": {},
   "source": [
    "# 出力層の設計\n",
    "ニューラルネットワークは分類問題と回帰問題のいずれにも用いることができる。しかし、どちらに用いるかによって出力層の活性化関数を変更する必要がある。  \n",
    "一般的に回帰問題では恒等関数を、分類問題ではソフトマックス関数を用いる。  \n",
    "回帰問題はある入力データから数値の予測を行うもの、分類問題とは名の通り入力したデータの分類をするものだ。\n",
    "# 恒等関数とシフトマックス関数\n",
    "恒等関数は入力をそのまま出力する。  \n",
    "    また、分類問題で使われるシフトマックス関数は以下の式であらわされる。(i=1と示したいが困難だったため妥協させていただく。)\n",
    " $$ \\frac{exp(a_{k})}{\\displaystyle\\sum_1^n exp(a_{i})}$$\n",
    " これはk番目の出力y<sub>k</sub>を表している。  \n",
    " ソフトマックス関数を実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cdc61ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])\n",
    "\n",
    "exp_a = np.exp(a)\n",
    "print(exp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "393be6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.1221542101633\n"
     ]
    }
   ],
   "source": [
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14b31326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bf2c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    exp_a =np.exp(a)\n",
    "    sum_exp_a = np_sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e91f28",
   "metadata": {},
   "source": [
    "これは式としては正しいがパソコンであるがゆえにオーバーフローを起こす、すなわち処理限界に到達してしまうことがある。  そこで以下のような改善案がある。なお∑の下の1はi=1を示していると考えていただきたい。\n",
    "$$y_{k}=\\frac{exp(a_{k})}{\\sum_1^nexp(a_{i})}\n",
    "        =\\frac{Cexp(a_{k})}{C\\sum_1^nexp(a_{i})}\n",
    "        =\\frac{exp(a_{k}+\\log_{}{C})}{\\sum_1^nexp(a_{i}+\\log_{}{C})}$$\n",
    "ここで述べたいことはシフトマックス関数はの指数関数の計算を行う際には、何らかの定数を足し算しても結果が変わらないということだ。ここでCにはそんな値を用いても問題がないが、オーバーフローの対策として入力信号の中で最大の数を用いることが一般的だ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "716bfc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TabPC\\AppData\\Local\\Temp/ipykernel_7172/2837122526.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(a) / np.sum(np.exp(a))\n",
      "C:\\Users\\TabPC\\AppData\\Local\\Temp/ipykernel_7172/2837122526.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.exp(a) / np.sum(np.exp(a))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1010, 1000, 999])\n",
    "np.exp(a) / np.sum(np.exp(a)) #正しく計算されない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "339d2eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, -10, -11])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.max(a)#1010\n",
    "a - c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09617736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99937902e-01, 4.53971105e-05, 1.67006637e-05])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(a - c) /np.sum(np.exp(a - c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5757296",
   "metadata": {},
   "source": [
    "このように普通の計算ではnan(不定)であったところを入力信号の最大値を引くことで正しく計算することができていることが分かる。以上を踏まえてソフトマックス関数を実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2010d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)#オーバーフロー対策\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y\n",
    "#ソフトマックス関数を用いるとニューラルネットワークの出力は以下のように計算できる。\n",
    "\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "y = softmax(a)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5211310",
   "metadata": {},
   "source": [
    "ここで示したようにソフトマックス関数は0から1の間の実数になる。また、ソフトマックス関数の出力の総和は1となる。すなわち、ソフトマックス関数の出力は確率としてみることができる。  \n",
    "    一般にニューラルネットワークのクラス分類では出力の最も大きいニューロンに相当するクラスだけを認識結果とする。そして、ソフトマックス関数を適応しても出力の最も大きなニューロンの場所は変わらない。よってニューラルネットワークが分類を行う際にはソフトマックス関を省略できます。実際の問題ではコンピューターの計算量が増えるためソフトマックス関数は省略するのが一般的だ。\n",
    "# 出力層のニューロン数\n",
    "出力層のニューロンの数は解くべき問題に応じて適宜決める必要がある。クラス分類を行う問題では出力層のニューロン数を分類したいクラス数に設定するのが一般的だ。\n",
    "# MNISTデータセット\n",
    "MNISTデータセットとは手書き数字の画像セットだ。MNISTは機械学習の分野で最も有名なデータセットのひとつ。読んだ本ではMNISTデータセットのダウンロードから画像データのNumPy配列への変換までをサポートする便利なPythonスクリプト、mnist.pyを提供しているため、利用する。  　\n",
    "以下は手書き数字認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94fe4483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "447a7462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = image.fromarray(np.unit8(img))\n",
    "    pil_img.show()\n",
    "    \n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "img =x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b63d4a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(28, 28)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'fromarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7172/384142840.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimg_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7172/3057202499.py\u001b[0m in \u001b[0;36mimg_show\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimg_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpil_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mpil_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'fromarray'"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "img = img.reshape(28, 28)\n",
    "print(img.shape)\n",
    "\n",
    "img_show(img) #失敗しました"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d218df",
   "metadata": {},
   "source": [
    "ここで注意することはflatten=trueとして読み込んだ画像はNumPy配列として一次元で格納されていること。そのため、画像の表示には元の形状である28×28にする必要がある。\n",
    "# ニューラルネットワークの推論処理\n",
    "ここで、このMNISTデータセットに対して推論処理をするニューラルネットワークを実装する。  \n",
    "入力層を784(28<sup>2</sup>)個、出力層は10個(0～9)とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2bf8664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "        \n",
    "        return network\n",
    "    \n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1,W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) +b3\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "    \n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y)\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "        \n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x))) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91190ce2",
   "metadata": {},
   "source": [
    "# バッチ処理\n",
    "まとめてn個のデータを入れることができ、その時n個のデータを出力する。  \n",
    "この時、まとまりのある入力データをバッチと呼ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79472390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

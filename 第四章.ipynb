{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf92a465",
   "metadata": {},
   "source": [
    "# 学習\n",
    "訓練データから最適な重みパラメーターのsタイを自動で獲得することを学習という。  \n",
    "そのためには**損失関数**という指標の導入が必要である。  \n",
    "この損失関数を基準として、元雄も値が小さくなる重みパラメーターを探し出すことが学習の目的だ。  \n",
    "今回はもっとも小さな損失関数の値を求める手段として勾配法と呼ばれる関数の傾きを用いた手法を使う。\n",
    "# データから学習する\n",
    "ニューラルネットワークの特徴はデータから学習できる点にある。このことで重みパラメーターを自動で定めることができる。  \n",
    "実際のニューラルネットワークではパラメーターが数千、数万とあるため、これはあたしたちにとって朗報であるといえる。\n",
    "# データ駆動　\n",
    "一般的に問題を解決するときは人が様々なことを考えて仕事をするが、機械学習による手法では人の介入を極力避けて集めたデータから答えを見つけようと試みる。また、ニューラルネットワークやディープラーニングでは従来の機械学習以上に人の介入を遠ざける重要な性質を持ち合わせる。  \n",
    "手書きされた文字「５」を認識するアルゴリズムの一つに画像から**特徴量**を抽出して、そのパターンを学習することが考えられる。特徴量とは入力データから本質的なデータを的確に抽出できるように設計した変換機ことである。  \n",
    "なお、画像の特徴量は一般にベクトルを用いて記述される。コンピュータビジョンの分野で有名な特徴量にはSIFT,SUREやHOGがあげられる。このような特徴量を用いて画像データをベクトルに変換して、その変換されたベクトルに対して機械学習で使われる識別器(SVM,KNN)などで学習されることができる。  \n",
    "この機械学習によるアプローチでは集められたデータの中から「機械」が規則性を見つけ出す。これはゼロからアルゴリズムを考え出す場合と比べると効率的で、人にとっても楽に感じる。しかし、画像をベクトルに変換するときに使用した特徴量は人が設計したものであることに注意が必要である。なぜなら問題に応じて適切な特徴量を使わないと良い結果を得られないからだ。ニューラルネットワーク(ディープラーニング)によるアプローチは人の介在しない手段である。\n",
    "# 訓練データとテストデータ\n",
    "機械学習においては訓練データ(教師データとも呼ばれる)とテストデータの二つに分けて学習や実験を行う。なぜなら訓練データとテストデータに同一のものを用いると**汎用能力**があるか分からないからだ。汎用能力とはまだ見ぬデータに対する能力のことだ。\n",
    "# 損失関数\n",
    "ニューラルネットワークは一つの指標を手掛かりに最適なパラメーターを探索する。ニューラルネットワークの学習に用いる関数は損失関数と呼ばれる。この関数には任意の関数を用いることができるが、一般には二乗和誤差や交差エントロピー誤差などが用いられる。\n",
    "# 二乗和誤差\n",
    "二乗和誤差ではニューラルネットワークの出力y<sub>k</sub>とt<sub>k</sub>の差の二乗の1/2の総和を求める。これが小さいほど教師データに適合した値が出るといえる。なお、正解ラベルを1,それ以外を0であらわす方法をone-hot表現という。また、引数y,kにはNumpy配列を用いる。\n",
    "# 交差エントロピー法\n",
    "tをone-hot表現を用いて示して、y<sub>k</sub>をニューラルネットワークの出力として、総和が1であるとする。\n",
    "$$E=-\\sum_k^{} t_{k} log (y_{k})$$\n",
    "と表す。こうすると正解ラベルがつくつくべき時の自然対数状の確率が求まる。自然対数は真数が大きいほど値が大きくなるので、正解ラベルがつくときにニューラルネットワークでの出力が大きいときほど損失関数の値は小さくなる。またlog0となるのを回避するために真数には微小な値であるdeltaを足す必要がある。\n",
    "# ミニバッチ学習\n",
    "実際の機械学習ではすべての訓練データに対して損失関数を求める必要がある。\n",
    "%%E=\\frac{1}{N}\\sum_n^{}\\sum_k^{} t_{nk}\\log_{}{y_{nk}}$$\n",
    " しかしビックデータなどとなるとすべてのデータ対象の損失関数の平均を求めるのは現実的でない。そのため、N個のデータからM個のデータを無作為に選んでそのM個のデータを用いて学習を行うことをミニバッチ学習という。np.random.choice()を用いることで指定された数字からランダムの数だけ取り出すことができる。\n",
    "バッチ対応交差エントロピー誤差は理解できませんでした。\n",
    "\n",
    "# 損失関数が必要なわけ\n",
    "損失関数ではなく精度認識にしたほうがいいと考える人もいるかもしれないが、それではいけない。  \n",
    "なぜならを最適なパラメーターを探すときに損失関数を微分(勾配)して重みとバイアス最適の値を調節して求めることとなるが、制度認識ではほとんどの場所で０となってしまうからだ。損失関数では微分しても0となることはほぼないため、損失関数を用いている。  \n",
    "なぜ精度認識を微分すると大体の場所で0になるかというと、パラメーターを多少変えても精度認識は変化がなく、変わったとして非連続的な動きをするからだ。これはシグモイド関数とステップ関数の間にも同じことが言える。\n",
    "# 微分\n",
    "微分についても既習なので省略させていただく。  \n",
    "微分における微小な値hはコンピューター上では10<sub>-4</sub>程度の値を用いることがベストといわれている。高尾の値が小さすぎると**丸め誤差**という少数の小さな値において数値が省略されることが問題となってくる。  \n",
    "なお、hを無限にに近づけることができないため、数学的な厳密な微分とは異なる値が現れる。これを解消するために(x+h)と(x-h)での関数ｆの差分を計算することで誤差を減らせる。\n",
    "# 偏微分\n",
    "偏微分では1変数の微分と同じである場所の傾きを調べる。ただし偏微分の場合複数ある変数の中でターゲットとする変数を一つに絞り、ほかの変数はある値に固定する。  \n",
    "全ての変数の偏微分をベクトルとしてまとめたものを勾配という。勾配はベクトル(矢印)をもって図上に示される。一方で注意が必要なこととしてはその場所から低くなる方向を示すのであって、決して一番低いところを必ずさすわけではないことに注意。\n",
    "# 勾配法\n",
    "損失関数は複雑でパラメーターが多いため、どこで最小値を取るのか不明である。そこで勾配を用いて最小値を取るところを探そうというのが勾配法の趣旨である。ここでゃ勾配が最小値を示すわけではないことに特に注意する。特に複雑な損失関数では最小値を示すことはまれである。しかし、勾配の低くなる方向へ行くことで関数の値を減らせることは確かであるため、勾配の情報を手掛かりに進む方向を決めるのがよい。  \n",
    "勾配法はある地点から勾配の進む方向へ行き、それを繰り返すことで関数の値を徐々に減らす方法だ。特にニューラルネットワークでよく使われる。\n",
    "    $$x_{0}=x_{0} - \\eta\\frac{\\partial f}{\\partial x_{0}}$$このように勾配法はあらわされる。以上の式のnのようなものは更新の量を表す。これはニューラルネットワークにおいては学習率と呼ばれる、一回の学習でどれだけ学習するかを定めるのが学習率である、学習量は多すぎても小さすぎても問題であるため、適切な値であるか確認作業しながら行うのが一般的である。例えば、学習量が多すぎると大きな値へ発散してしまい、小さすぎるとほとんど更新されずに終わってしまう。\n",
    "# ニューラルネットワークに対する勾配\n",
    "w<sub>1</sub>を変化させることで損失関数がどのように変化するかを勾配を用いて計算することができる。つぎに、偏微分しても形状は変わらない。  \n",
    "simpleNetというクラスは形状が2×3の重みパラメーターを一つだけインスタンス変数として持つ。また二つのメソッドがあり、一つは予測するためのメソッドpredict(x),もうひとつは損失関数の値を求めるためのloss(x,t)。なお、xには入力データが、tには正解ラベルが入っているものとする。\n",
    "# 学習アルゴリズムの実装\n",
    "## 前提\n",
    "ニューラルネットワークには適応可能な重みとバイアスがあり、この重みとバイアスを訓練データに適応するように調節することを学習と呼ぶ、\n",
    "## ステップ１\n",
    "学習データから一部のデータを選び出す。それをミニバッチという。処理するデータを減らすためにある。\n",
    "## ステップ２\n",
    "ミニバッチの損失関数を減らすために重みパラメーターを勾配を調べる。\n",
    "## ステップ３\n",
    "重みパラメーターを勾配方向に微小量だけ更新する。  \n",
    "## 繰り返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64fda1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
